{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Copy of DP_ODQA.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa_aw3ZiSKmN",
        "colab_type": "text"
      },
      "source": [
        "# Open-domain question answering with DeepPavlov\n",
        "\n",
        "\n",
        "The architecture of the DeepPavlov ODQA skill is modular and consists of two components: a **ranker** and a **reader**. In order to answer any question, the **ranker** first retrieves a few relevant articles from the article collection, and then the **reader** scans them carefully to identify the answer. The **ranker** is based on DrQA [1] proposed by Facebook Research. Specifically, the DrQA approach uses unigram-bigram hashing and TF-IDF matching designed to efficiently return a subset of relevant articles based on a question. The **reader** is based on R-NET [2] proposed by Microsoft Research Asia and its implementation by Wenxuan Zhou. The R-NET architecture is an end-to-end neural network model that aims to answer questions based on a given article. R-NET first matches the question and the article via gated attention-based recurrent networks to obtain a question-aware article representation. Then the self-matching attention mechanism refines the representation by matching the article against itself, which effectively encodes information from the whole article. Finally, the pointer networks locate the positions of answers in the article. The scheme below shows DeepPavlov ODQA system architecture.\n",
        "\n",
        "DeepPavlov’s ODQA system has two Wikipedia-based models. The first one is based on the English Wikipedia dump from 2018-02-11 (5,180,368 articles) and the second one is based on the Russian Wikipedia dump from 2018-04-01 (1,463,888 articles).\n",
        "\n",
        "[1] [Chen, Danqi, et al. \"Reading wikipedia to answer open-domain questions.\" arXiv preprint arXiv:1704.00051 (2017)](https://arxiv.org/pdf/1704.00051.pdf)\n",
        "\n",
        "[2] [R-NET: Machine reading comprehension with self-matching networks](https://www.microsoft.com/en-us/research/wp-content/uploads/2017/05/r-net.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jj7898EGSKmV",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://github.com/deepmipt/dp_notebooks/blob/master/odqa.png?raw=1\">\n",
        "\n",
        "<center>Picture 1. The DeepPavlov-based ODQA system architecture</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAiC_1LoSKmc",
        "colab_type": "text"
      },
      "source": [
        "# Model Requirements\n",
        "\n",
        "The DeepPavlov ODQA system has two Wikipedia-based models. The English Wikipedia model requires 35 GB of local storage, whereas the Russian version takes up about 20 GB. The Wikipedia dumps can be rebuilt by steps described in the [documentation](http://docs.deeppavlov.ai/en/0.1.6/components/tfidf_ranking.html#available-data-and-pretrained-models). Both models require about 24 GB of RAM. It is possible to run them on a 16 GB machine, but the swap size should be at least 8 GB.\n",
        " \n",
        "But first, install DeepPavlov and all the model's requirements."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kgyF9yYSKmh",
        "colab_type": "code",
        "outputId": "f6a2ce95-6efd-44ac-be64-b54e3caef101",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install -q deeppavlov\n",
        "!python -m deeppavlov install ru_odqa_infer_wiki"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 778kB 2.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 20.1MB 1.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 7.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 665kB 50.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 7.3MB 19.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 8.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 7.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 6.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 9.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.1MB 49.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 10.4MB 47.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 4.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 8.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 8.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 8.0MB 30.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.5MB 46.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.7MB 40.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 256kB 53.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.7MB 42.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 7.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 7.1MB 12.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 47.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 9.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 7.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.9MB 35.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 153kB 54.6MB/s \n",
            "\u001b[?25h  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pytelegrambotapi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for starlette (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for httptools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.0.0; python_version >= \"3.0\", but you'll have pandas 0.25.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.21.0, but you'll have requests 2.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "2020-04-26 09:05:06.257 INFO in 'deeppavlov.core.common.file'['file'] at line 32: Interpreting 'ru_odqa_infer_wiki' as '/usr/local/lib/python3.6/dist-packages/deeppavlov/configs/odqa/ru_odqa_infer_wiki.json'\n",
            "Collecting tensorflow==1.15.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/d9/fd234c7bf68638423fb8e7f44af7fcfce3bcaf416b51e6d902391e47ec43/tensorflow-1.15.2-cp36-cp36m-manylinux2010_x86_64.whl (110.5MB)\n",
            "\u001b[K     |████████████████████████████████| 110.5MB 112kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.1.0)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 36.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.12.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (3.10.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (0.34.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.18.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 44.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (3.2.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (0.2.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.0.8)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (0.9.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.28.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (0.8.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.15.2) (46.1.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.2.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.2) (2.10.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=fcc27ca282e6d7a271fe83570f3a2b6b8ffd98ab994f3fd7fcf7df639b2971a2\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.10.0rc0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-estimator, gast, tensorboard, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 2.2.0\n",
            "    Uninstalling tensorflow-estimator-2.2.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorboard 2.2.1\n",
            "    Uninstalling tensorboard-2.2.1:\n",
            "      Successfully uninstalled tensorboard-2.2.1\n",
            "  Found existing installation: tensorflow 2.2.0rc3\n",
            "    Uninstalling tensorflow-2.2.0rc3:\n",
            "      Successfully uninstalled tensorflow-2.2.0rc3\n",
            "Successfully installed gast-0.2.2 tensorboard-1.15.0 tensorflow-1.15.2 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFaGyTgKSKm2",
        "colab_type": "text"
      },
      "source": [
        "# Model Description\n",
        "\n",
        "The architecture of the ODQA skill is modular and consists of two components, a **ranker** and a **reader**. In order to answer any question, the **reader** first retrieves **top_n** relevant articles from the document collection, and then the **reader** scans them carefully to identify the answer. The detailed description of the ODQA models can be found in the [DeepPavlov documentation](http://docs.deeppavlov.ai/en/0.1.6/skills/odqa.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bep0MSEcSKm8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load https://github.com/deepmipt/DeepPavlov/blob/0.1.6/deeppavlov/configs/odqa/ru_odqa_infer_wiki.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLm7Bus4SKnJ",
        "colab_type": "text"
      },
      "source": [
        "# Interacting with the model\n",
        "\n",
        "**As it was mentioned, the Wikipedia-based models have significant storage and RAM requirements, therefore it's impossible to interact with them on Colab, however you can do so localy (of course when the requirements are satisfied). Alternatively, you can check out our [demo](http://demo.ipavlov.ai/).**\n",
        "\n",
        "Make sure that you can navigate the configuration files by using Autocomplete (Tab key) with **configs** module."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKOxzPFQSKnN",
        "colab_type": "raw"
      },
      "source": [
        "from deeppavlov import configs\n",
        "from deeppavlov.core.commands.infer import build_model\n",
        "\n",
        "odqa = build_model(configs.odqa.en_odqa_infer_wiki, download = True)\n",
        "answers = odqa([\n",
        "                \"Where did guinea pigs originate?\", \n",
        "                \"When did the Lynmouth floods happen?\",\n",
        "                \"When is the Bastille Day?\"\n",
        "                ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUv_1GK-SKnR",
        "colab_type": "text"
      },
      "source": [
        "# Training the model\n",
        "\n",
        "You can train a model by running the framework with **train** parameter, wherein the model will be trained on the document collection defined in the **dataset_reader** section of the configuration file. The **dataset_reader** section of the ranker’s configuration defines the source of the articles. The source can be of the following **dataset_format-**:\n",
        "\n",
        "wiki — the Wikipedia dump,\n",
        "txt — the path to the separated text files,\n",
        "json — JSON files, which should be formatted as a list with dicts that contain the *title* and *doc* keywords.\n",
        "\n",
        "\n",
        "* *wiki* - The Wikipedia dump\n",
        "* *txt* - each document in separate txt file\n",
        "* *json* - JSON files should be formatted as list with dicts which contain 'title' and 'doc' keywords.\n",
        "\n",
        "As a training corpus, I will use the PloS sentence corpus. It consists of 300 computational biology articles, each of them stored in a separate *txt* file. For simplicity, we will use the same configuration files that is used for the Wikipedia-based ODQA system; however, we strongly encourage you to create custom configuration files for your own models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9ZHJcyZSKnW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !wget -q http://archive.ics.uci.edu/ml/machine-learning-databases/00311/SentenceCorpus.zip\n",
        "# !unzip SentenceCorpus.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70ueR5S-SKnk",
        "colab_type": "text"
      },
      "source": [
        "In order to fit a model on new data, first, change the **data_path** parameter of the **dataset_reader** section. Then change the **dataset_format** to *txt*. Finally, train the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imTgwHdOSKnq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from deeppavlov import configs\n",
        "# from deeppavlov.core.common.file import read_json\n",
        "# from deeppavlov import configs, train_model\n",
        "\n",
        "# model_config = read_json(configs.doc_retrieval.en_ranker_tfidf_wiki)\n",
        "# model_config[\"dataset_reader\"][\"data_path\"] = \"/content/SentenceCorpus/unlabeled_articles/plos_unlabeled\"\n",
        "# model_config[\"dataset_reader\"][\"dataset_format\"] = \"txt\"\n",
        "# doc_retrieval = train_model(model_config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWUnGhC1SKoC",
        "colab_type": "text"
      },
      "source": [
        "Examine the ranker output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gM6B7g0PSKoM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# doc_retrieval(['cerebellum'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUEAsDiYSKos",
        "colab_type": "text"
      },
      "source": [
        "Everything is done to run the ODQA component, make sure that the **download = False** otherwise the pretrained Wikipedia dump will overwrite your model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "gxw8TqVaSKow",
        "colab_type": "code",
        "outputId": "070d825c-554b-43e8-aa15-34a2fdbdda12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from deeppavlov import configs\n",
        "from deeppavlov.core.commands.infer import build_model\n",
        "\n",
        "# # Download all the SQuAD models\n",
        "# squad = build_model(configs.squad.multi_squad_noans_infer, download = True)\n",
        "# Do not download the ODQA models, we've just trained it\n",
        "odqa = build_model(configs.odqa.ru_odqa_infer_wiki, download = True) # = False \n",
        "answers = odqa([\"Что такое любовь?\", \"Как жить?\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-04-26 09:05:56.508 INFO in 'deeppavlov.core.data.utils'['utils'] at line 80: Downloading from http://files.deeppavlov.ai/embeddings/ft_native_300_ru_wiki_lenta_nltk_word_tokenize/ft_native_300_ru_wiki_lenta_nltk_word_tokenize.vec to /root/.deeppavlov/downloads/embeddings/ft_native_300_ru_wiki_lenta_nltk_word_tokenize.vec\n",
            "100%|██████████| 4.53G/4.53G [15:58<00:00, 4.73MB/s]\n",
            "2020-04-26 09:21:55.589 INFO in 'deeppavlov.core.data.utils'['utils'] at line 80: Downloading from http://files.deeppavlov.ai/embeddings/ft_native_300_ru_wiki_lenta_nltk_word_tokenize-char.vec to /root/.deeppavlov/downloads/embeddings/ft_native_300_ru_wiki_lenta_nltk_word_tokenize-char.vec\n",
            "100%|██████████| 4.52M/4.52M [00:01<00:00, 3.06MB/s]\n",
            "2020-04-26 09:21:57.765 INFO in 'deeppavlov.core.data.utils'['utils'] at line 80: Downloading from http://files.deeppavlov.ai/deeppavlov_data/ru_odqa.tar.gz to /root/.deeppavlov/ru_odqa.tar.gz\n",
            "100%|██████████| 1.19G/1.19G [03:16<00:00, 6.06MB/s]\n",
            "2020-04-26 09:25:14.480 INFO in 'deeppavlov.core.data.utils'['utils'] at line 242: Extracting /root/.deeppavlov/ru_odqa.tar.gz archive into /root/.deeppavlov/models\n",
            "2020-04-26 09:26:13.742 INFO in 'deeppavlov.core.data.utils'['utils'] at line 80: Downloading from http://files.deeppavlov.ai/datasets/wikipedia/ruwiki.tar.gz to /root/.deeppavlov/ruwiki.tar.gz\n",
            "100%|██████████| 1.52G/1.52G [07:16<00:00, 3.48MB/s]\n",
            "2020-04-26 09:33:30.588 INFO in 'deeppavlov.core.data.utils'['utils'] at line 242: Extracting /root/.deeppavlov/ruwiki.tar.gz archive into /root/.deeppavlov/downloads\n",
            "2020-04-26 09:34:50.890 INFO in 'deeppavlov.core.data.utils'['utils'] at line 80: Downloading from http://files.deeppavlov.ai/deeppavlov_data/squad_model_ru_1.4_cpu_compatible.tar.gz to /root/.deeppavlov/squad_model_ru_1.4_cpu_compatible.tar.gz\n",
            "100%|██████████| 533M/533M [02:55<00:00, 3.04MB/s]\n",
            "2020-04-26 09:37:46.446 INFO in 'deeppavlov.core.data.utils'['utils'] at line 242: Extracting /root/.deeppavlov/squad_model_ru_1.4_cpu_compatible.tar.gz archive into /root/.deeppavlov/models\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package perluniprops to /root/nltk_data...\n",
            "[nltk_data]   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data] Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "2020-04-26 09:37:56.911 INFO in 'deeppavlov.models.vectorizers.hashing_tfidf_vectorizer'['hashing_tfidf_vectorizer'] at line 264: Loading tfidf matrix from /root/.deeppavlov/models/odqa/ruwiki_tfidf_matrix.npz\n",
            "2020-04-26 09:39:25.95 INFO in 'deeppavlov.dataset_iterators.sqlite_iterator'['sqlite_iterator'] at line 57: Connecting to database, path: /root/.deeppavlov/downloads/odqa/ruwiki.db\n",
            "2020-04-26 09:39:42.512 INFO in 'deeppavlov.dataset_iterators.sqlite_iterator'['sqlite_iterator'] at line 112: SQLite iterator: The size of the database is 1463888 documents\n",
            "2020-04-26 09:39:42.530 INFO in 'deeppavlov.models.preprocessors.squad_preprocessor'['squad_preprocessor'] at line 310: SquadVocabEmbedder: loading saved tokens vocab from /root/.deeppavlov/models/squad_model_ru/emb/vocab_embedder.pckl\n",
            "2020-04-26 09:39:48.838 INFO in 'deeppavlov.models.preprocessors.squad_preprocessor'['squad_preprocessor'] at line 310: SquadVocabEmbedder: loading saved chars vocab from /root/.deeppavlov/models/squad_model_ru/emb/char_vocab_embedder.pckl\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:37: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:193: The name tf.train.AdadeltaOptimizer is deprecated. Please use tf.compat.v1.train.AdadeltaOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/common/check_gpu.py:29: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/squad/squad.py:224: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/squad/squad.py:102: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/squad/squad.py:139: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-04-26 09:39:54.232 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 615: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py:122: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/layers/tf_layers.py:591: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/layers/tf_layers.py:596: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py:133: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py:139: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py:155: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/layers/tf_layers.py:808: calling reverse_sequence (from tensorflow.python.ops.array_ops) with seq_dim is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "seq_dim is deprecated, use seq_axis instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py:507: calling reverse_sequence (from tensorflow.python.ops.array_ops) with batch_dim is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "batch_dim is deprecated, use batch_axis instead\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-04-26 09:39:56.38 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 615: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
            "2020-04-26 09:39:56.169 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 615: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
            "2020-04-26 09:39:56.261 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 615: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/squad/utils.py:87: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/squad/utils.py:101: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/squad/utils.py:171: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/squad/utils.py:139: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/squad/squad.py:203: The name tf.matrix_band_part is deprecated. Please use tf.linalg.band_part instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/squad/squad.py:212: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:232: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:127: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:127: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/clip_ops.py:172: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/squad/squad.py:93: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:50: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-04-26 09:40:09.210 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /root/.deeppavlov/models/squad_model_ru/model]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:54: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/squad_model_ru/model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/deeppavlov/models/doc_retrieval/logit_ranker.py:65: FutureWarning: LogitRanker.__call__() API will be changed in the future release. Instead of returning Tuple(List[str], List[float] will return Tuple(List[List[str]], List[List[float]]).\n",
            "  ' Tuple(List[List[str]], List[List[float]]).', FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bm6Uus4uZWkI",
        "colab_type": "code",
        "outputId": "9ee846fd-aa24-4936-da90-ee3dd899db54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "answers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['спокойствие, новый художественный идеал', 'в финал Кубка Англии']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLWuV5MRXxmU",
        "colab_type": "code",
        "outputId": "6778dd86-3034-4016-da5c-56a13dc437f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# answers = odqa([\"What is Tuberculosis?\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/deeppavlov/models/doc_retrieval/logit_ranker.py:65: FutureWarning: LogitRanker.__call__() API will be changed in the future release. Instead of returning Tuple(List[str], List[float] will return Tuple(List[List[str]], List[List[float]]).\n",
            "  ' Tuple(List[List[str]], List[List[float]]).', FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgHLkHNRX45b",
        "colab_type": "code",
        "outputId": "98c361dd-c197-4593-e84c-7be24b472746",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "answers "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['спокойствие, новый художественный идеал', 'в финал Кубка Англии']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTYBb8KnTspU",
        "colab_type": "code",
        "outputId": "71ee121a-525a-4151-e9a0-881c77ae0d48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "# mount a folder\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yc11e2VXVZy5",
        "colab_type": "code",
        "outputId": "e60a8811-d3b4-4994-b70c-3d127e897269",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "%cd 'My Drive'\n",
        "%cd Diploma\n",
        "%cd data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/My Drive\n",
            "/gdrive/My Drive/Maga\n",
            "/gdrive/My Drive/Maga/Diploma\n",
            "/gdrive/My Drive/Maga/Diploma/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MD7YiYP9Zf5",
        "colab_type": "code",
        "outputId": "47ee2408-497b-4a34-9457-fb9de78b6774",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd Answers/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/My Drive/Maga/Diploma/data/Answers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsl8cqvU89Eb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "# os.chdir(\"Processed_ege_report\")\n",
        "\n",
        "direc = os.getcwd() # Get current working directory\n",
        "ext = '.json' # Select your file delimiter\n",
        "\n",
        "# Select only files with the ext extension\n",
        "txt_files = [i for i in os.listdir(direc) if os.path.splitext(i)[1] == ext]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZROwfoyO89P6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# collect all small files into one list\n",
        "import json\n",
        "\n",
        "\n",
        "big_list = [] # Create an empty list, \n",
        "\n",
        "# Iterate over your json files\n",
        "for f in txt_files:\n",
        "    # Open them and assign k and v in them to big_dict\n",
        "    with open(os.path.join(direc,f), 'r') as file_object:\n",
        "        for i, item in enumerate(json.load(file_object)):\n",
        "            big_list.append(item)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzCI-jus9LCA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "big_list[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPAd1pzQlj1s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import json\n",
        "\n",
        "# dl = json.load(open(\"open_9368.json\", \"r\", encoding=\"utf-8\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whhJctuoAgct",
        "colab_type": "code",
        "outputId": "70a9bcb4-de87-49bd-a81e-dbbcb3e13b49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# for i, di in enumerate(dl):\n",
        "#   if di[\"open_q\"] == \"В каком году родился Дмитрий Фёдорович Устинов?\":\n",
        "#     print(i)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6241\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfoAQc6BnPgK",
        "colab_type": "code",
        "outputId": "0a2b9c5b-856c-49b8-fed7-9450429be1d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "dl[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Q': 'Q142917',\n",
              " 'answer_open': 'Евгений Викторович Вучетич',\n",
              " 'atr': 'Q557355',\n",
              " 'ent': 'Родина-мать (Киев)',\n",
              " 'open_q': 'Кто создал скульптуру «Родина-мать»?',\n",
              " 'rel': 'P84',\n",
              " 'rel_r': 'архитектор (P84)',\n",
              " 'type': 'author',\n",
              " 'what': 'колоссальная статуя'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGep1bnem9sa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "questions = [d['open_q'] for d in dl]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SWy1Ye7nYAe",
        "colab_type": "code",
        "outputId": "b6a750af-eaab-49b2-e635-aba5322e6c12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "questions[10:13]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Кто был режиссёром фильма «Ирония судьбы, или С лёгким паром!»?',\n",
              " 'Кто снял фильм «Ирония судьбы, или С лёгким паром!»?',\n",
              " 'В каком году было Цусимское сражение?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4Lrr9TjnbMa",
        "colab_type": "code",
        "outputId": "abeccd97-f057-487e-cb55-bcd928e58945",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "answers = odqa(questions[10:11])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/deeppavlov/models/doc_retrieval/logit_ranker.py:65: FutureWarning: LogitRanker.__call__() API will be changed in the future release. Instead of returning Tuple(List[str], List[float] will return Tuple(List[List[str]], List[List[float]]).\n",
            "  ' Tuple(List[List[str]], List[List[float]]).', FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Q5CbHvnwvyN",
        "colab_type": "code",
        "outputId": "5c6cfdac-fe79-4e03-9618-d18fab8e4db5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "answers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Раиса Александровна Лукина']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nT15n8Bi2DUN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch(iterable, n=1):\n",
        "    l = len(iterable)\n",
        "    for ndx in range(0, l, n):\n",
        "        yield iterable[ndx:min(ndx + n, l)]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPT5n24g1qSz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tnrange, tqdm_notebook # might work\n",
        "from time import sleep\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "count = 0\n",
        "\n",
        "\n",
        "dirName = 'Answers' # add below\n",
        "if not os.path.exists(dirName):\n",
        "    os.mkdir(dirName)\n",
        "    print(\"Directory \" , dirName ,  \" Created \")\n",
        "else:    \n",
        "    print(\"Directory \" , dirName ,  \" already exists\")\n",
        "    \n",
        "\n",
        "for j in tqdm_notebook(batch(dl[6248:],10), desc='a loop'):\n",
        "  pack = []\n",
        "  for i, d in enumerate(j):\n",
        "    print(d)\n",
        "    d['answer_dp'] = odqa([d['open_q']])\n",
        "    pack.append(d)\n",
        "\n",
        "  name = datetime.utcnow().strftime('%Y-%m-%d %H_%M_%S.%f')[:-3]\n",
        "  filename = \"Answers/%s.json\"%name\n",
        "  with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(pack, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcZm_ThGzzg2",
        "colab_type": "code",
        "outputId": "3bb1b1b3-4c90-427e-e2cd-0f2043d26b2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "answers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Раиса Александровна Лукина', 'Раиса Александровна', 'около 14:30']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVUNeKsInwTN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "\n",
        "with open(\"answers_open_dp.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(answers, f, ensure_ascii=False, indent=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q48T5HdMoc3v",
        "colab_type": "code",
        "outputId": "c1fc2ffe-fc15-4b30-d639-6b6cfeaccf47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        }
      },
      "source": [
        "for i, d in enumerate(dl):\n",
        "  d['answer_dp'] = answers[i]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-86d15436582e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'answer_dp'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manswers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjZ7D8-Uodur",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "\n",
        "with open(\"open_with_dp_answers.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(dl, f, ensure_ascii=False, indent=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSU9u09wqrUg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsy9QfSLSKo-",
        "colab_type": "text"
      },
      "source": [
        "# Useful links\n",
        "\n",
        "[DeepPavlov repository](https://github.com/deepmipt/DeepPavlov)\n",
        "\n",
        "[DeepPavlov demo page](https://demo.ipavlov.ai)\n",
        "\n",
        "[DeepPavlov documentation](https://docs.deeppavlov.ai)"
      ]
    }
  ]
}